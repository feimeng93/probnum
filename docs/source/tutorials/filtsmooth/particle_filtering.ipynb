{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "final-drive",
   "metadata": {},
   "source": [
    "# Particle filtering\n",
    "\n",
    "In this tutorial we explain how to use `ProbNum` for particle filtering.\n",
    "We assume that you have read the tutorial on non-linear filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hearing-cosmetic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from probnum import filtsmooth, randvars, statespace, diffeq, randprocs\n",
    "from probnum.problems import TimeSeriesRegressionProblem\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "leading-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "skilled-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make inline plots vector graphics instead of raster graphics\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "set_matplotlib_formats(\"pdf\", \"svg\")\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"../../probnum.mplstyle\")\n",
    "\n",
    "# Consistent plotting styles for particles and for \"true\" latent states\n",
    "particle_style = {\n",
    "    \"color\": \"C1\",\n",
    "    \"marker\": \"o\",\n",
    "    \"markersize\": 5,\n",
    "    \"linestyle\": \"None\",\n",
    "    \"alpha\": 0.5,\n",
    "}\n",
    "latent_state_style = {\"color\": \"C0\", \"linewidth\": 5, \"linestyle\": \"-\", \"alpha\": 0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-ethiopia",
   "metadata": {},
   "source": [
    "## Pendulum\n",
    "\n",
    "We begin with setting up the pendulum problem, which is a standard non-linear test problem. The code below is taken from the non-linear filtering notebook.\n",
    "\n",
    "We begin by assembling a `DiscreteGaussian` as a model of the prior dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "improving-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = 2\n",
    "observation_dim = 1\n",
    "\n",
    "# approx. gravitational constant\n",
    "g = 9.81\n",
    "delta_t = 0.05\n",
    "\n",
    "\n",
    "def pendulum_rhs(state):\n",
    "    \"\"\"Right-hand side of an ODE that defines pendulum dynamics\"\"\"\n",
    "    x1, x2 = state\n",
    "    y1 = x1 + x2 * delta_t\n",
    "    y2 = x2 - g * np.sin(x1) * delta_t\n",
    "    return np.array([y1, y2])\n",
    "\n",
    "\n",
    "def pendulum_jacobian(state):\n",
    "    \"\"\"Jacobian of the pendulum ODE\"\"\"\n",
    "    x1, x2 = state\n",
    "    dy1_dx = [1.0, delta_t]\n",
    "    dy2_dx = [-g * np.cos(x1) * delta_t, 1.0]\n",
    "    return np.array([dy1_dx, dy2_dx])\n",
    "\n",
    "\n",
    "dynamics_transition_function = lambda t, state: pendulum_rhs(state)\n",
    "dynamics_transition_jacobian_function = lambda t, state: pendulum_jacobian(state)\n",
    "\n",
    "dynamics_diffusion_matrix = 1.0 * (\n",
    "    np.diag(np.array([delta_t ** 3 / 3, delta_t]))\n",
    "    + np.diag(np.array([delta_t ** 2 / 2]), 1)\n",
    "    + np.diag(np.array([delta_t ** 2 / 2]), -1)\n",
    ")\n",
    "\n",
    "# Create discrete, non-linear Gaussian dynamics model\n",
    "dynamics_model = statespace.DiscreteGaussian(\n",
    "    input_dim=state_dim,\n",
    "    output_dim=state_dim,\n",
    "    state_trans_fun=dynamics_transition_function,\n",
    "    proc_noise_cov_mat_fun=lambda t: dynamics_diffusion_matrix,\n",
    "    jacob_state_trans_fun=dynamics_transition_jacobian_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-cartoon",
   "metadata": {},
   "source": [
    "Next, we set up the measurement model as another discrete, non-linear Gaussian transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "graphic-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pendulum_measurement(state):\n",
    "    x1, x2 = state\n",
    "    return np.array([np.sin(x1)])\n",
    "\n",
    "\n",
    "def pendulum_measurement_jacobian(state):\n",
    "    x1, x2 = state\n",
    "    return np.array([[np.cos(x1), 0.0]])\n",
    "\n",
    "\n",
    "measurement_function = lambda t, state: pendulum_measurement(state)\n",
    "measurement_jacobian_function = lambda t, state: pendulum_measurement_jacobian(state)\n",
    "\n",
    "measurement_variance = 0.12 ** 2\n",
    "measurement_covariance = measurement_variance * np.eye(observation_dim)\n",
    "\n",
    "# Create discrete, non-linear Gaussian measurement model\n",
    "measurement_model = statespace.DiscreteGaussian(\n",
    "    input_dim=state_dim,\n",
    "    output_dim=observation_dim,\n",
    "    state_trans_fun=measurement_function,\n",
    "    proc_noise_cov_mat_fun=lambda t: measurement_covariance,\n",
    "    jacob_state_trans_fun=measurement_jacobian_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-lawsuit",
   "metadata": {},
   "source": [
    "Finally, we define the initial distribution: a Gaussian random variable. We also generate some artificial observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "diagnostic-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_0 = np.ones(state_dim)\n",
    "sigma_0 = measurement_variance * np.eye(state_dim)\n",
    "initial_state_rv = randvars.Normal(mean=mu_0, cov=sigma_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excess-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_grid = np.arange(0.0, 3.5, step=delta_t)\n",
    "latent_states, observations = statespace.generate_samples(\n",
    "    dynmod=dynamics_model,\n",
    "    measmod=measurement_model,\n",
    "    initrv=initial_state_rv,\n",
    "    times=time_grid,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "distributed-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_problem = TimeSeriesRegressionProblem(\n",
    "    observations=observations,\n",
    "    locations=time_grid,\n",
    "    measurement_models=[measurement_model] * len(time_grid),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-success",
   "metadata": {},
   "source": [
    "Now we're essentially good to go. With this setup we could do non-linear Gaussian filtering (extended Kalman filtering, unscented Kalman filtering), but here, we avoid the Gaussian approximations and do particle filtering.\n",
    "\n",
    "To construct a particle filter, we provide prior, measurement model, and initial RV as well as\n",
    "\n",
    "* The number of particles: `num_particles`. The larger the better, but also the larger the slower (it is Monte Carlo approximation, after all).\n",
    "* A linearized measurement model that is used as an importance density: `linearized_measurement_model`. In ProbNum we implement two types of particle filters: a bootstrap particle filter, that uses the prior as an importance distribution (which always works, but also requires a lot of particles -- this is what is used in `linearized_measurement_model` is left empty), and a particle filter that uses an approximate Gaussian filter as an importance density. In the pendulum example, we do the latter, because the extended Kalman filter has already been proven to be successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "outside-guest",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 10\n",
    "prior_process = randprocs.MarkovProcess(\n",
    "    transition=dynamics_model, initrv=initial_state_rv, initarg=-1.0\n",
    ")\n",
    "importance_distribution = filtsmooth.LinearizationImportanceDistribution.from_ekf(\n",
    "    dynamics_model, forward_implementation=\"sqrt\",  backward_implementation=\"sqrt\"\n",
    ")\n",
    "\n",
    "# Construct the PF\n",
    "pf = filtsmooth.ParticleFilter(\n",
    "    prior_process,\n",
    "    importance_distribution=importance_distribution,\n",
    "    num_particles=num_particles,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-potato",
   "metadata": {},
   "source": [
    "The remainder is the same `.filter()` interface that we know from Gaussian filtering.\n",
    "After applying this method, we plot the mode of the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "distinguished-controversy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 1.0 0.0\n",
      "-1.0 1.0 0.0\n",
      "[[nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]\n",
      " [nan nan]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-47f4a8e626ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m posterior, _ = pf.filter(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mregression_problem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;32m~/Programmes/probnum/probnum/src/probnum/filtsmooth/_particlefiltsmooth/_particle_filter.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, regression_problem)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0minfo_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregression_problem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0mfiltered_rvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0minfo_dicts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programmes/probnum/probnum/src/probnum/filtsmooth/_particlefiltsmooth/_particle_filter.py\u001b[0m in \u001b[0;36mfilter_generator\u001b[0;34m(self, regression_problem)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mparticle_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimportance_rv_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             for idx, (importance_rv, dynamics_rv, p, w) in enumerate(\n\u001b[0m\u001b[1;32m    167\u001b[0m                 \u001b[0mparticle_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             ):\n",
      "\u001b[0;32m~/Programmes/probnum/probnum/src/probnum/filtsmooth/_particlefiltsmooth/_particle_filter.py\u001b[0m in \u001b[0;36mimportance_rv_generator\u001b[0;34m(self, measmod, particles, weights, data, t_old, dt, t)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparticles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             output = self.importance_distribution.generate_importance_rv(\n\u001b[0m\u001b[1;32m    233\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_old\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeasurement_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeasmod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             )\n",
      "\u001b[0;32m~/Programmes/probnum/probnum/src/probnum/filtsmooth/_particlefiltsmooth/_importance_distributions.py\u001b[0m in \u001b[0;36mgenerate_importance_rv\u001b[0;34m(self, particle, data, t, dt, measurement_model)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mrealization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         )\n\u001b[0;32m--> 128\u001b[0;31m         importance_rv, info[\"lin_update_info\"] = lin_measmod.backward_realization(\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mrealization_obtained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdynamics_rv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         )\n",
      "\u001b[0;32m~/Programmes/probnum/probnum/src/probnum/filtsmooth/_gaussfiltsmooth/_extendedkalman.py\u001b[0m in \u001b[0;36mbackward_realization\u001b[0;34m(self, realization_obtained, rv, rv_forwarded, gain, t, dt, _diffusion, _linearise_at)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0m_linearise_at\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     ):\n\u001b[0;32m---> 75\u001b[0;31m         return self._backward_realization_via_backward_rv(\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mrealization_obtained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mrv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programmes/probnum/probnum/src/probnum/statespace/transition.py\u001b[0m in \u001b[0;36m_backward_realization_via_backward_rv\u001b[0;34m(self, realization, *args, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0mreal_as_rv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandvars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msupport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrealization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_rv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_as_rv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_realization_via_forward_rv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programmes/probnum/probnum/src/probnum/filtsmooth/_gaussfiltsmooth/_extendedkalman.py\u001b[0m in \u001b[0;36mbackward_rv\u001b[0;34m(self, rv_obtained, rv, rv_forwarded, gain, t, dt, _diffusion, _linearise_at)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mcompute_jacobian_at\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_linearise_at\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m_linearise_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinearized_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mat_this_rv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_jacobian_at\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         return self.linearized_model.backward_rv(\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0mrv_obtained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv_obtained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mrv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programmes/probnum/probnum/src/probnum/statespace/discrete_transition.py\u001b[0m in \u001b[0;36mbackward_rv\u001b[0;34m(self, rv_obtained, rv, rv_forwarded, gain, t, _diffusion, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     ):\n\u001b[0;32m--> 293\u001b[0;31m         return self._backward_implementation(\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0mrv_obtained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv_obtained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mrv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programmes/probnum/probnum/src/probnum/statespace/discrete_transition.py\u001b[0m in \u001b[0;36m_backward_rv_sqrt\u001b[0;34m(self, rv_obtained, rv, rv_forwarded, gain, t, _diffusion)\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mR1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbig_triu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mR12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbig_triu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mgain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve_triangular\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mnew_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgain\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrv_obtained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstate_trans\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programmes/probnum/pnenv/lib/python3.8/site-packages/scipy/linalg/basic.py\u001b[0m in \u001b[0;36msolve_triangular\u001b[0;34m(a, b, trans, lower, unit_diagonal, overwrite_b, debug, check_finite)\u001b[0m\n\u001b[1;32m    331\u001b[0m              'versions of SciPy.', DeprecationWarning, stacklevel=2)\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m     \u001b[0mb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0ma1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programmes/probnum/pnenv/lib/python3.8/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'masked arrays are not supported'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mtoarray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobjects_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'O'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programmes/probnum/pnenv/lib/python3.8/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AllFloat'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    486\u001b[0m             \"array must not contain infs or NaNs\")\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "posterior, _ = pf.filter(\n",
    "    regression_problem,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    time_grid, np.sin(latent_states[:, 0]), **latent_state_style, label=\"Latent state\"\n",
    ")\n",
    "plt.plot(\n",
    "    time_grid,\n",
    "    np.sin(posterior.states.mode[:, 0]),\n",
    "    **particle_style,\n",
    "    label=\"Mode of posterior\"\n",
    ")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(r\"$x$\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-praise",
   "metadata": {},
   "source": [
    "It seems that the true latent state is recovered fairly well.\n",
    "The RMSE of the mode is also much smaller than the RMSE of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-affair",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_mode = np.linalg.norm(\n",
    "    np.sin(posterior.states.mode[:, 0]) - np.sin(latent_states[:, 0])\n",
    ")\n",
    "rmse_data = np.linalg.norm(observations - np.sin(latent_states[:, 0]))\n",
    "print(f\"Mode of PF: \\t{rmse_mode}\\nObservations: \\t{rmse_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-county",
   "metadata": {},
   "source": [
    "The strength of a particle filter is not the point estimate, but the posterior distribution. \n",
    "Let us look at a few more particles. Since we want to exclude the unlikely states from the visualization, we resample the posterior before plotting.\n",
    "This way, only those states that have sufficient probability to be resampled are shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unlikely particles by resampling the posterior\n",
    "resampled_states = posterior.states.resample()\n",
    "\n",
    "plt.plot(\n",
    "    time_grid, np.sin(latent_states[:, 0]), **latent_state_style, label=\"Latent state\"\n",
    ")\n",
    "plt.plot(\n",
    "    time_grid,\n",
    "    np.sin(resampled_states.support[:, :, 0]),\n",
    "    **particle_style,\n",
    "    label=\"Particles\"\n",
    ")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(r\"$x$\")\n",
    "\n",
    "# Remove duplicate legend entries before showing the legend\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "configured-uniform",
   "metadata": {},
   "source": [
    "It seems that the distribution nicely concentrates around the true state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-individual",
   "metadata": {},
   "source": [
    "## ODEs\n",
    "\n",
    "Particle filters can also be used to solve ODEs (in a very basic way -- if you need a reliant method, use the ODE solvers in `diffeq` instead).\n",
    "\n",
    "Let us consider a Bernoulli equation,\n",
    "$$\n",
    "\\dot y(t) = 1.5 (y - y^3), \\quad y(0) \\approx 0,\n",
    "$$\n",
    "\n",
    "which has two stable equilibria: one at $\\pm 1$ each, which are reached depending on the sign of the initial value. There is also an unstable equilibrium at $0.$.\n",
    "\n",
    "We begin by setting up this ODE in the language of `probnum.diffeq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-sally",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bern_rhs(t, x):\n",
    "    return 1.5 * (x - x ** 3)\n",
    "\n",
    "\n",
    "def bern_jac(t, x):\n",
    "    return np.array([1.5 * (1 - 3 * x ** 2)])\n",
    "\n",
    "\n",
    "t0, tmax = 0.0, 6.0\n",
    "initrv = randvars.Constant(np.array([0.0]))\n",
    "bernoulli = diffeq.IVP([t0, tmax], initrv, rhs=bern_rhs, jac=bern_jac)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-compiler",
   "metadata": {},
   "source": [
    "We will not go into detail about how to turn an ODE into a filtering problem, but in a nutshell: you need a `statespace.Integrator` prior, and a measurement model that \"punishes\" the discrepancy of the ODE $\\dot y - f(y)$. We construct both. As an initial random variable we choose a Gaussian random variable (whose dimension must match the dimension of the prior, not of the ODE!). We add a bit of \"evaluation variance\" (`evlvar`), because the particle filter struggles with noise-free observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "likely-laundry",
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamod = statespace.IBM(ordint=2, spatialdim=1, forward_implementation=\"sqrt\")\n",
    "measmod = statespace.DiscreteGaussian.from_ode(bernoulli, dynamod, evlvar=0.00001)\n",
    "\n",
    "initmean = np.array([0.0, 0, 0.0])\n",
    "initcov = 0.0125 * np.diag([1, 1.0, 1.0])\n",
    "initrv = randvars.Normal(initmean, initcov, cov_cholesky=np.sqrt(initcov))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-questionnaire",
   "metadata": {},
   "source": [
    "As in the pendulum example, we use an extended Kalman filter importance distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-hammer",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_particles = 50\n",
    "ode_prior = randprocs.MarkovProcess(transition=dynamod, initrv=initrv, initarg=0.0)\n",
    "importance = filtsmooth.LinearizationImportanceDistribution.from_ekf(\n",
    "    dynamod, backward_implementation=\"sqrt\", forward_implementation=\"sqrt\"\n",
    ")\n",
    "\n",
    "ode_pf = filtsmooth.ParticleFilter(\n",
    "    ode_prior,\n",
    "    importance_distribution=importance,\n",
    "    num_particles=num_particles,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cloudy-thomas",
   "metadata": {},
   "source": [
    "The ODE filtering problem consists of evenly spaced points and data that is equal to zero. The rest is `ParticleFilter.filter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forbidden-extent",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_locs = 50\n",
    "data = np.zeros((num_locs, 1))\n",
    "locs = np.linspace(0.0, tmax, num_locs)\n",
    "\n",
    "regression_problem = TimeSeriesRegressionProblem(\n",
    "    observations=data, locations=locs, measurement_models=[measmod] * len(data)\n",
    ")\n",
    "\n",
    "ode_posterior, _ = ode_pf.filter(regression_problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secret-demand",
   "metadata": {},
   "source": [
    "We plot the entire set of particles. Again, we resample in order to exclude the unlikely particles from the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-trace",
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "plt.axhline(+1, **latent_state_style, label=\"Stable equilibrium\")\n",
    "plt.axhline(0.0, linestyle=\"dotted\", alpha=0.5, label=\"Unstable equilibrium\")\n",
    "plt.axhline(-1, **latent_state_style)\n",
    "plt.xlabel(r\"$t$\")\n",
    "plt.ylabel(r\"$y(t)$\")\n",
    "plt.plot(\n",
    "    locs, ode_posterior.states.resample().support[:, :, 0], **particle_style, label=\"Particles\"\n",
    ")\n",
    "\n",
    "# Remove duplicate legend entries\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-surge",
   "metadata": {},
   "source": [
    "Depending on the position of the initial particle (which is a sample from the initial random variable), the trajectories either approach +1 or -1. Eventually, they all get there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-locator",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Particle filtering seamlessly blends into the filtering and smoothing code in ProbNum. It can be constructed with the same ingredients as a Gaussian filter, but of course there are fewer restrictions on tractability in those models (any non-linear discrete model works well).\n",
    "Choices are the bootstrap filter (if `linearized_measurement_model` is left empty) or one with a Gaussian filter used as an importance density (if e.g. `DiscreteUKFComponent` or `DiscreteEKFComponent`) are provided.\n",
    "\n",
    "Its results infer the true latent states well on simple problems, and the family of particles displays differnet paths of the potential solution (which is especially evident in the ODE example)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
